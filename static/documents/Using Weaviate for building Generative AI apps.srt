1
00:00:05,339 --> 00:00:07,200
um great to be here with everybody

2
00:00:07,200 --> 00:00:09,420
I'm just going to provide a 10 15 minute

3
00:00:09,420 --> 00:00:13,679
up uh quick intro to what wev8 is and

4
00:00:13,679 --> 00:00:15,660
because this is a hackathon I won't be

5
00:00:15,660 --> 00:00:17,520
doing a lot of talking I'll just uh show

6
00:00:17,520 --> 00:00:19,920
you code and show you what uh what you

7
00:00:19,920 --> 00:00:21,840
can accomplish with bv8

8
00:00:21,840 --> 00:00:23,820
so aviate is an open source Vector

9
00:00:23,820 --> 00:00:27,900
database and a vector database I'm

10
00:00:27,900 --> 00:00:29,099
assuming a lot of people know what this

11
00:00:29,099 --> 00:00:31,199
is but I'll give a quick uh one minute

12
00:00:31,199 --> 00:00:35,399
recap of this so a vector database like

13
00:00:35,399 --> 00:00:38,399
we V8 essentially how it works is you

14
00:00:38,399 --> 00:00:40,379
start off with your encoder models so

15
00:00:40,379 --> 00:00:42,420
these are machine learning models that

16
00:00:42,420 --> 00:00:44,640
any one of these companies like cohere

17
00:00:44,640 --> 00:00:48,360
open AI hugging face host and create

18
00:00:48,360 --> 00:00:51,840
you take these machine learning models

19
00:00:51,840 --> 00:00:55,199
and you essentially pass your data

20
00:00:55,199 --> 00:00:56,699
through these and this can be any

21
00:00:56,699 --> 00:00:58,800
unstructured data right this can be text

22
00:00:58,800 --> 00:01:02,219
images audio any type of data that you

23
00:01:02,219 --> 00:01:03,600
can imagine you can pass through these

24
00:01:03,600 --> 00:01:06,659
models and you take the vectors that

25
00:01:06,659 --> 00:01:08,159
come out of these models the embeddings

26
00:01:08,159 --> 00:01:10,140
and you can put them into a vector

27
00:01:10,140 --> 00:01:12,680
database like

28
00:01:13,080 --> 00:01:14,640
um and the reason why you would want to

29
00:01:14,640 --> 00:01:17,280
do this is because now you have a

30
00:01:17,280 --> 00:01:18,900
numerical representation of all your

31
00:01:18,900 --> 00:01:21,780
data you can take a query you can

32
00:01:21,780 --> 00:01:23,580
vectorize it through that exact same

33
00:01:23,580 --> 00:01:26,520
model put it into a vector database and

34
00:01:26,520 --> 00:01:29,159
then now you can do near object search

35
00:01:29,159 --> 00:01:31,439
we don't the vector database will

36
00:01:31,439 --> 00:01:34,740
understand what your data means it knows

37
00:01:34,740 --> 00:01:36,119
how

38
00:01:36,119 --> 00:01:38,520
close concepts are and then how how far

39
00:01:38,520 --> 00:01:41,280
they are as well

40
00:01:41,280 --> 00:01:44,820
and so classically this is the end of it

41
00:01:44,820 --> 00:01:47,280
you can you can query your vector

42
00:01:47,280 --> 00:01:48,900
database and you get a list of results

43
00:01:48,900 --> 00:01:51,540
and you send that back to the user but

44
00:01:51,540 --> 00:01:53,340
because this is DPAC and we're

45
00:01:53,340 --> 00:01:54,840
interested in deep learning what I

46
00:01:54,840 --> 00:01:56,720
thought I'd do is I'd put a spin on this

47
00:01:56,720 --> 00:01:59,820
and really what we'd like to do instead

48
00:01:59,820 --> 00:02:02,939
of outputting our results to users

49
00:02:02,939 --> 00:02:04,200
is

50
00:02:04,200 --> 00:02:07,320
we want to conduct Vector search in this

51
00:02:07,320 --> 00:02:09,179
domain here

52
00:02:09,179 --> 00:02:12,239
but we want to pass the output to a

53
00:02:12,239 --> 00:02:14,340
large language Model A generative AI

54
00:02:14,340 --> 00:02:17,280
model that can build on top of the

55
00:02:17,280 --> 00:02:20,280
context that we've given it and so the

56
00:02:20,280 --> 00:02:22,140
greatest application of this is in

57
00:02:22,140 --> 00:02:24,180
generative search where I'm sure all of

58
00:02:24,180 --> 00:02:26,879
you have heard about chat GPT

59
00:02:26,879 --> 00:02:29,819
um so I'll demo how you can use weeviate

60
00:02:29,819 --> 00:02:32,760
with chat GPT and the main idea behind

61
00:02:32,760 --> 00:02:35,819
this is that chat CPT by itself cannot

62
00:02:35,819 --> 00:02:38,520
be used on your own data so it's read

63
00:02:38,520 --> 00:02:40,860
everything so it has a very uh a wide

64
00:02:40,860 --> 00:02:42,120
general knowledge

65
00:02:42,120 --> 00:02:44,519
but let's say you have proprietary

66
00:02:44,519 --> 00:02:46,440
company documents or you have personal

67
00:02:46,440 --> 00:02:48,780
documents track TPT doesn't know about

68
00:02:48,780 --> 00:02:50,700
them it hasn't read it

69
00:02:50,700 --> 00:02:52,500
what you can do is you can take all

70
00:02:52,500 --> 00:02:55,560
those documents vectorize them and store

71
00:02:55,560 --> 00:02:57,480
them into eviate if your documents are

72
00:02:57,480 --> 00:02:59,340
not already vectorized then we have

73
00:02:59,340 --> 00:03:01,319
separate modules that you can choose to

74
00:03:01,319 --> 00:03:04,260
vectorize those put them into eviate and

75
00:03:04,260 --> 00:03:05,700
then given a prompt that you would

76
00:03:05,700 --> 00:03:08,160
usually give to chat GPT you can send

77
00:03:08,160 --> 00:03:11,099
that prompt to ev8 and then we can

78
00:03:11,099 --> 00:03:12,959
filter through those documents and give

79
00:03:12,959 --> 00:03:16,560
you relevant documents and now along

80
00:03:16,560 --> 00:03:19,260
with the prompt to chat TPT you can also

81
00:03:19,260 --> 00:03:21,540
send these relevant documents so it can

82
00:03:21,540 --> 00:03:25,040
add it can answer the question

83
00:03:25,040 --> 00:03:27,720
grounded in the context of these

84
00:03:27,720 --> 00:03:30,180
filtered documents right

85
00:03:30,180 --> 00:03:32,040
and so this is how you get a customized

86
00:03:32,040 --> 00:03:35,400
response out of chat GPT

87
00:03:35,400 --> 00:03:36,420
um I know there might be a lot of

88
00:03:36,420 --> 00:03:39,900
questions about the retrieval plugin the

89
00:03:39,900 --> 00:03:41,580
retrieval plugin essentially gives you

90
00:03:41,580 --> 00:03:44,040
the same functionality we're working

91
00:03:44,040 --> 00:03:46,519
with openai to develop that as we speak

92
00:03:46,519 --> 00:03:50,159
but for now for this hackathon uh we'll

93
00:03:50,159 --> 00:03:52,920
make the generative module generative

94
00:03:52,920 --> 00:03:55,200
openai module accessible to everybody

95
00:03:55,200 --> 00:03:58,140
here so and and I'll demo that in just a

96
00:03:58,140 --> 00:04:00,360
second so that you can work with leviate

97
00:04:00,360 --> 00:04:03,599
and and chat GPT as well

98
00:04:03,599 --> 00:04:05,700
okay so that's that's all the Talking

99
00:04:05,700 --> 00:04:08,040
that I wanted to do I just wanted to go

100
00:04:08,040 --> 00:04:10,620
over to uh to my code now and give you

101
00:04:10,620 --> 00:04:12,959
guys a quick demo

102
00:04:12,959 --> 00:04:17,160
all right so I put this demo together uh

103
00:04:17,160 --> 00:04:18,900
last night and I wanted to demonstrate

104
00:04:18,900 --> 00:04:20,760
the uh some of the most powerful

105
00:04:20,760 --> 00:04:22,740
features of leviate here

106
00:04:22,740 --> 00:04:26,400
I'm going to demonstrate the python vva

107
00:04:26,400 --> 00:04:28,380
client but there we have a ton of other

108
00:04:28,380 --> 00:04:30,600
clients that you can go to our website

109
00:04:30,600 --> 00:04:33,500
and you can check out

110
00:04:34,020 --> 00:04:35,580
um but the only thing you need to get

111
00:04:35,580 --> 00:04:37,860
set up for this demo is the leviate

112
00:04:37,860 --> 00:04:39,900
client so you can install that using

113
00:04:39,900 --> 00:04:41,400
this and you want to make sure that

114
00:04:41,400 --> 00:04:43,919
you're up to date with the with the most

115
00:04:43,919 --> 00:04:46,460
recent client here

116
00:04:46,460 --> 00:04:50,759
uh and uh to get a instance of V8 going

117
00:04:50,759 --> 00:04:53,639
you can go to you can go to the WCS

118
00:04:53,639 --> 00:04:54,960
Cloud you can make an account here and

119
00:04:54,960 --> 00:04:57,840
you can create a free instance here uh

120
00:04:57,840 --> 00:04:59,220
the only limitation is that you will

121
00:04:59,220 --> 00:05:00,720
only be able to store a hundred thousand

122
00:05:00,720 --> 00:05:03,180
objects but for a hackathon that should

123
00:05:03,180 --> 00:05:05,400
be uh fairly good and and that'll be

124
00:05:05,400 --> 00:05:07,560
online for 14 days and you can query as

125
00:05:07,560 --> 00:05:09,960
much as you like

126
00:05:09,960 --> 00:05:11,880
um for this particular demo we're going

127
00:05:11,880 --> 00:05:14,460
to be using a model from a company

128
00:05:14,460 --> 00:05:15,960
called cohere

129
00:05:15,960 --> 00:05:17,759
and obviously we're going to be using

130
00:05:17,759 --> 00:05:19,740
generative search so we need a open AP

131
00:05:19,740 --> 00:05:23,340
openai API key

132
00:05:23,340 --> 00:05:26,220
so I've created uh I've created a

133
00:05:26,220 --> 00:05:28,740
leviate cluster here in preparation for

134
00:05:28,740 --> 00:05:30,960
this for this demo

135
00:05:30,960 --> 00:05:32,699
um some of the details here I've

136
00:05:32,699 --> 00:05:34,380
uploaded a hundred thousand objects to

137
00:05:34,380 --> 00:05:35,820
this cluster and these are just

138
00:05:35,820 --> 00:05:38,639
Wikipedia articles so I took a very big

139
00:05:38,639 --> 00:05:40,680
data set and I chunked off a hundred

140
00:05:40,680 --> 00:05:42,539
thousand objects I put it into eviate

141
00:05:42,539 --> 00:05:44,759
and I'll show you what we can accomplish

142
00:05:44,759 --> 00:05:46,620
with this

143
00:05:46,620 --> 00:05:49,500
so the very first thing I did here was I

144
00:05:49,500 --> 00:05:51,960
created a database schema I specified

145
00:05:51,960 --> 00:05:55,440
what I want to put into my database and

146
00:05:55,440 --> 00:05:57,840
in this case because my data is already

147
00:05:57,840 --> 00:06:00,479
vectorized I don't need leviate to

148
00:06:00,479 --> 00:06:01,800
vectorize it for me if it wasn't

149
00:06:01,800 --> 00:06:03,300
vectorized you could enable

150
00:06:03,300 --> 00:06:05,400
vectorization and it would take a little

151
00:06:05,400 --> 00:06:06,419
longer

152
00:06:06,419 --> 00:06:09,840
but you would still be able to uh pop

153
00:06:09,840 --> 00:06:13,320
the data in in a in a batch and then

154
00:06:13,320 --> 00:06:15,840
vectorize as you go it's just quicker if

155
00:06:15,840 --> 00:06:18,539
it's already vectorized

156
00:06:18,539 --> 00:06:20,880
we create the database schema

157
00:06:20,880 --> 00:06:23,340
and then this is the data set that we're

158
00:06:23,340 --> 00:06:25,680
working with here and as you can see

159
00:06:25,680 --> 00:06:28,440
it's just uh Wikipedia articles that are

160
00:06:28,440 --> 00:06:30,800
chunked into paragraphs

161
00:06:30,800 --> 00:06:33,300
and these are already we've already got

162
00:06:33,300 --> 00:06:35,460
the embeddings the vectorization is

163
00:06:35,460 --> 00:06:38,400
generated for us here

164
00:06:38,400 --> 00:06:41,039
and this is a multilingual data set so I

165
00:06:41,039 --> 00:06:43,080
think this uh particular data set has

166
00:06:43,080 --> 00:06:46,319
over 50 different languages that you can

167
00:06:46,319 --> 00:06:48,539
that you can use and this is one of the

168
00:06:48,539 --> 00:06:50,039
reasons why we're using a cohere model

169
00:06:50,039 --> 00:06:51,900
because it interprets multiple languages

170
00:06:51,900 --> 00:06:53,759
as well

171
00:06:53,759 --> 00:06:55,860
once you've got your data set loaded up

172
00:06:55,860 --> 00:06:58,740
you can configure the batch operation so

173
00:06:58,740 --> 00:07:01,620
you when you upload data to ev8 you it

174
00:07:01,620 --> 00:07:03,120
batches it and then it uploads it in

175
00:07:03,120 --> 00:07:05,100
batches so we're going to upload a

176
00:07:05,100 --> 00:07:08,699
hundred data data points at a time

177
00:07:08,699 --> 00:07:11,880
and then this is our uploading process

178
00:07:11,880 --> 00:07:14,819
so I ran this so now I've got a hundred

179
00:07:14,819 --> 00:07:17,220
thousand objects which is what my VBA

180
00:07:17,220 --> 00:07:19,259
cloud service dashboard was showing

181
00:07:19,259 --> 00:07:20,639
before

182
00:07:20,639 --> 00:07:23,580
uh and then from this point on it's it's

183
00:07:23,580 --> 00:07:25,680
mainly just about querying right so once

184
00:07:25,680 --> 00:07:27,660
you've got this in this is a one-time

185
00:07:27,660 --> 00:07:29,880
deal once you've got that data in now

186
00:07:29,880 --> 00:07:31,740
you can query all you want so here I've

187
00:07:31,740 --> 00:07:34,199
created a semantic search function

188
00:07:34,199 --> 00:07:37,319
that I'll demonstrate in just a second

189
00:07:37,319 --> 00:07:40,020
um I'm going to be demonstrating uh

190
00:07:40,020 --> 00:07:42,479
keyword search so classical search I'm

191
00:07:42,479 --> 00:07:44,220
going to do semantic search as well as

192
00:07:44,220 --> 00:07:45,660
generative search but there's a lot of

193
00:07:45,660 --> 00:07:47,580
other search modalities that we support

194
00:07:47,580 --> 00:07:49,560
so you can do hybrid search where you

195
00:07:49,560 --> 00:07:52,199
can combine semantic search as well as

196
00:07:52,199 --> 00:07:54,180
classic word search

197
00:07:54,180 --> 00:07:55,020
um

198
00:07:55,020 --> 00:07:57,660
so if you want to learn more about that

199
00:07:57,660 --> 00:07:59,940
all that information is available in the

200
00:07:59,940 --> 00:08:01,500
documentation

201
00:08:01,500 --> 00:08:04,139
so the most simplest search that we can

202
00:08:04,139 --> 00:08:06,000
do here is we get we can look for the

203
00:08:06,000 --> 00:08:08,940
word avocado and

204
00:08:08,940 --> 00:08:10,680
here

205
00:08:10,680 --> 00:08:14,460
oh one second live demo error let me

206
00:08:14,460 --> 00:08:17,580
rerun this okay there we go

207
00:08:17,580 --> 00:08:19,560
so here all it's doing is it's looking

208
00:08:19,560 --> 00:08:21,960
for an article that has the word avocado

209
00:08:21,960 --> 00:08:24,300
in it right so nothing special any any

210
00:08:24,300 --> 00:08:27,120
uh database can do this

211
00:08:27,120 --> 00:08:28,740
um where it gets interesting is when you

212
00:08:28,740 --> 00:08:31,500
start to do semantic search right uh in

213
00:08:31,500 --> 00:08:34,020
semantic search you can type in a a

214
00:08:34,020 --> 00:08:37,380
query and it will return to you in this

215
00:08:37,380 --> 00:08:39,000
case I've limited to five so it only

216
00:08:39,000 --> 00:08:41,099
returns five articles the five most

217
00:08:41,099 --> 00:08:43,080
relevant articles to this particular

218
00:08:43,080 --> 00:08:46,080
search and it also gives you a measure

219
00:08:46,080 --> 00:08:49,500
of distance between your query and the

220
00:08:49,500 --> 00:08:51,180
article right so you can quantify how

221
00:08:51,180 --> 00:08:55,800
similar uh a a returned article is

222
00:08:55,800 --> 00:08:58,320
so this is fairly good I I didn't have

223
00:08:58,320 --> 00:09:00,600
the word python in here but it returned

224
00:09:00,600 --> 00:09:01,740
to me that the python is the most

225
00:09:01,740 --> 00:09:04,740
popular machine learning language

226
00:09:04,740 --> 00:09:06,899
because this is also multilingual and I

227
00:09:06,899 --> 00:09:08,220
thought this would be a great

228
00:09:08,220 --> 00:09:10,920
application specifically because

229
00:09:10,920 --> 00:09:13,860
um we're in India you can ask it a

230
00:09:13,860 --> 00:09:16,920
prompt in Hindi and so this is uh Hindi

231
00:09:16,920 --> 00:09:19,980
for good movies and it will work just as

232
00:09:19,980 --> 00:09:22,320
well because the model understands Hindi

233
00:09:22,320 --> 00:09:23,580
it understands a lot of different

234
00:09:23,580 --> 00:09:25,200
languages

235
00:09:25,200 --> 00:09:27,720
so I think there's a lot a lot of

236
00:09:27,720 --> 00:09:31,220
creative stuff that you can do with this

237
00:09:32,279 --> 00:09:36,300
there's also so another example here you

238
00:09:36,300 --> 00:09:39,779
can ask it for uh famous vacation spots

239
00:09:39,779 --> 00:09:43,620
in Farsi and that works just as well

240
00:09:43,620 --> 00:09:46,080
I'm a big Cricket fan and this is the

241
00:09:46,080 --> 00:09:48,680
first talk that I'm giving in India so

242
00:09:48,680 --> 00:09:51,060
uh there's no way that my demo wasn't

243
00:09:51,060 --> 00:09:53,220
going to be about qriket so here I've

244
00:09:53,220 --> 00:09:56,040
put together a bunch of examples of

245
00:09:56,040 --> 00:09:57,720
generative search so the first thing I'm

246
00:09:57,720 --> 00:09:59,339
going to do is look through a hundred

247
00:09:59,339 --> 00:10:03,000
thousand Wikipedia documents and see uh

248
00:10:03,000 --> 00:10:04,620
what it comes up with if I ask about

249
00:10:04,620 --> 00:10:07,320
famous cricketers from India

250
00:10:07,320 --> 00:10:09,240
so here you get some of the famous

251
00:10:09,240 --> 00:10:11,580
cricketers you get multiple matches here

252
00:10:11,580 --> 00:10:14,339
because the Wikipedia articles are

253
00:10:14,339 --> 00:10:16,740
chunked into paragraphs okay

254
00:10:16,740 --> 00:10:19,399
and so

255
00:10:19,620 --> 00:10:22,680
uh and so oh that there's a question is

256
00:10:22,680 --> 00:10:24,720
it using cosine based similarity yes

257
00:10:24,720 --> 00:10:26,820
it's using well in this case it's using

258
00:10:26,820 --> 00:10:30,080
the dot product actually

259
00:10:32,820 --> 00:10:36,120
and then so here the metric that that

260
00:10:36,120 --> 00:10:37,800
this particular model was trained to

261
00:10:37,800 --> 00:10:40,740
optimize is the is the dot product

262
00:10:40,740 --> 00:10:43,140
so this is semantic search what I refer

263
00:10:43,140 --> 00:10:46,200
to in my um in my slides was you can

264
00:10:46,200 --> 00:10:48,779
take a hundred thousand articles you can

265
00:10:48,779 --> 00:10:51,779
pass in a prompt and then take the

266
00:10:51,779 --> 00:10:54,240
filtered articles here so these five

267
00:10:54,240 --> 00:10:56,399
filtered articles and you can pass them

268
00:10:56,399 --> 00:10:58,680
off to chat GPT and you can ask it to

269
00:10:58,680 --> 00:11:02,519
conduct or generate a output or answer a

270
00:11:02,519 --> 00:11:03,360
task

271
00:11:03,360 --> 00:11:06,180
taking these in as context and this is

272
00:11:06,180 --> 00:11:08,220
where it gets really cool these are some

273
00:11:08,220 --> 00:11:10,800
of the functionalities that chat GPT and

274
00:11:10,800 --> 00:11:12,360
the retrieval plugin that they've

275
00:11:12,360 --> 00:11:15,839
recently announced cater to as well

276
00:11:15,839 --> 00:11:18,660
soon that is going to be available with

277
00:11:18,660 --> 00:11:20,399
vv8 we're actually working on that right

278
00:11:20,399 --> 00:11:23,640
now but uh for now what you can use is

279
00:11:23,640 --> 00:11:26,880
the generative open AI module that we've

280
00:11:26,880 --> 00:11:28,680
put together and it works in a similar

281
00:11:28,680 --> 00:11:30,660
manner so let's break this down first

282
00:11:30,660 --> 00:11:31,620
here

283
00:11:31,620 --> 00:11:33,660
so what I'm going to do is I'm going to

284
00:11:33,660 --> 00:11:35,579
generate a prompt and this is the prompt

285
00:11:35,579 --> 00:11:37,980
for chat CPT so this is what I'm going

286
00:11:37,980 --> 00:11:39,779
to send to chat GPT

287
00:11:39,779 --> 00:11:41,820
and then what I do is instead of sending

288
00:11:41,820 --> 00:11:43,740
this directly to chat CPT through their

289
00:11:43,740 --> 00:11:45,720
completions API

290
00:11:45,720 --> 00:11:48,360
I'm going to query my Vector database

291
00:11:48,360 --> 00:11:51,060
and I'm going to say give me all of the

292
00:11:51,060 --> 00:11:53,640
titles and texts for articles that have

293
00:11:53,640 --> 00:11:55,860
to do with famous cricketers from India

294
00:11:55,860 --> 00:11:58,680
and I'm going to limit it to 3 and I'm

295
00:11:58,680 --> 00:12:00,720
going to call this with generate single

296
00:12:00,720 --> 00:12:03,600
prompt generate method on this what this

297
00:12:03,600 --> 00:12:06,740
does is it takes each one of the three

298
00:12:06,740 --> 00:12:09,000
documents that are returned from leviate

299
00:12:09,000 --> 00:12:12,240
and it passes them to track GPT one at a

300
00:12:12,240 --> 00:12:15,000
time so that it can answer this question

301
00:12:15,000 --> 00:12:17,279
and now notice how I've embedded The

302
00:12:17,279 --> 00:12:20,279
Returned Concepts within the documents

303
00:12:20,279 --> 00:12:22,200
into the prompt so I can say write me

304
00:12:22,200 --> 00:12:24,540
some interview questions I can ask

305
00:12:24,540 --> 00:12:28,140
whatever the return title is and here's

306
00:12:28,140 --> 00:12:31,019
some information about them

307
00:12:31,019 --> 00:12:34,620
so if you run this prompt

308
00:12:34,620 --> 00:12:36,899
takes a while because I'm using the uh

309
00:12:36,899 --> 00:12:40,800
the openai API here

310
00:12:40,800 --> 00:12:42,540
so here the first thing I want to point

311
00:12:42,540 --> 00:12:44,220
out is that the relevant context here is

312
00:12:44,220 --> 00:12:47,160
Virat Kohli so through the hundred

313
00:12:47,160 --> 00:12:48,360
thousand documents when I search for

314
00:12:48,360 --> 00:12:49,920
famous cricketers the very first one I

315
00:12:49,920 --> 00:12:52,680
got was Virat Kohli and then what I said

316
00:12:52,680 --> 00:12:53,700
here was write me some interview

317
00:12:53,700 --> 00:12:56,700
questions that I can ask Virat Kohli and

318
00:12:56,700 --> 00:12:58,079
here's some information about them and

319
00:12:58,079 --> 00:13:02,160
this is their Wikipedia information

320
00:13:03,120 --> 00:13:07,700
and it generated as a result of this

321
00:13:07,700 --> 00:13:11,220
uh what questions you can ask him right

322
00:13:11,220 --> 00:13:12,959
you can do a lot of other cool things

323
00:13:12,959 --> 00:13:15,720
here as well right so you can ask take

324
00:13:15,720 --> 00:13:18,060
those same three uh cricketers and write

325
00:13:18,060 --> 00:13:20,220
me a heroic tale about them and you can

326
00:13:20,220 --> 00:13:22,079
send a send a list of their

327
00:13:22,079 --> 00:13:23,339
accomplishments

328
00:13:23,339 --> 00:13:26,420
and here you get

329
00:13:26,519 --> 00:13:28,740
so you get generated text about dravid

330
00:13:28,740 --> 00:13:32,459
and a story about him

331
00:13:32,459 --> 00:13:34,860
do the same thing about uh tendul's

332
00:13:34,860 --> 00:13:36,360
guide

333
00:13:36,360 --> 00:13:39,899
so this is one one returned response

334
00:13:39,899 --> 00:13:43,380
goes to chat TPT you generate a you

335
00:13:43,380 --> 00:13:44,880
answer a prompt with respect to that

336
00:13:44,880 --> 00:13:46,980
context right the other way that you can

337
00:13:46,980 --> 00:13:48,779
use degenerative search a generative

338
00:13:48,779 --> 00:13:51,600
module is you can take everything that

339
00:13:51,600 --> 00:13:54,300
your vector database returns wrap it up

340
00:13:54,300 --> 00:13:58,680
and send it to chatgpt through one

341
00:13:58,680 --> 00:14:00,480
prompt and so now it has to read through

342
00:14:00,480 --> 00:14:02,339
everything that was returned so if you

343
00:14:02,339 --> 00:14:03,660
return 10 articles it reads to

344
00:14:03,660 --> 00:14:05,579
everything and it answers one question

345
00:14:05,579 --> 00:14:07,440
it answers one prompt as a result of

346
00:14:07,440 --> 00:14:10,740
that so this is the uh the grouped task

347
00:14:10,740 --> 00:14:13,740
so here almost everything is the same

348
00:14:13,740 --> 00:14:15,660
except now what I'm doing is with

349
00:14:15,660 --> 00:14:18,779
generate I'm doing a group task and I'm

350
00:14:18,779 --> 00:14:22,800
returning 15 articles 15 paragraphs and

351
00:14:22,800 --> 00:14:24,720
it says here which of these cricketers

352
00:14:24,720 --> 00:14:27,000
uh in these uh text is the most

353
00:14:27,000 --> 00:14:29,459
accomplished and I wanted to choose at

354
00:14:29,459 --> 00:14:31,820
least one

355
00:14:32,399 --> 00:14:34,980
so here uh it shows me that these are

356
00:14:34,980 --> 00:14:37,139
the different articles that it found uh

357
00:14:37,139 --> 00:14:39,839
as a result of my search here Cricut

358
00:14:39,839 --> 00:14:41,820
there's a lot of them are relevant there

359
00:14:41,820 --> 00:14:43,260
are some irrelevant ones here as well

360
00:14:43,260 --> 00:14:45,660
right so it returns some Cricket insect

361
00:14:45,660 --> 00:14:47,880
ones as well

362
00:14:47,880 --> 00:14:50,459
but uh once you take all these articles

363
00:14:50,459 --> 00:14:52,199
and you pass them off to chat GPT it

364
00:14:52,199 --> 00:14:53,940
prints out a list

365
00:14:53,940 --> 00:14:57,180
great cricketers from those articles and

366
00:14:57,180 --> 00:14:58,680
you can do a lot of prompt engineering

367
00:14:58,680 --> 00:15:00,360
around this as well right so let's say I

368
00:15:00,360 --> 00:15:03,660
do this exact same prompt but now I add

369
00:15:03,660 --> 00:15:06,600
in uh choose at least one and explain

370
00:15:06,600 --> 00:15:09,959
why not just the not just their names

371
00:15:09,959 --> 00:15:12,540
but explain why they were chosen

372
00:15:12,540 --> 00:15:15,420
and if you run this

373
00:15:15,420 --> 00:15:18,420
it'll explain itself

374
00:15:18,420 --> 00:15:21,480
so out of that list that we just saw uh

375
00:15:21,480 --> 00:15:24,060
it picks Tendulkar and then it has a it

376
00:15:24,060 --> 00:15:26,399
has a lot of context around why it's

377
00:15:26,399 --> 00:15:28,500
picking to nuclear because we're passing

378
00:15:28,500 --> 00:15:31,380
in the the text that the vector database

379
00:15:31,380 --> 00:15:33,180
sent out

380
00:15:33,180 --> 00:15:35,480
uh there's a question in the chat about

381
00:15:35,480 --> 00:15:37,980
multi-tenancy if I have multiple users

382
00:15:37,980 --> 00:15:39,540
clients on my platform should I create

383
00:15:39,540 --> 00:15:42,000
separate indices for each of them or

384
00:15:42,000 --> 00:15:44,399
should I store the user ID and leviate

385
00:15:44,399 --> 00:15:48,480
and filter by user ID for every query uh

386
00:15:48,480 --> 00:15:49,980
one second let me understand this

387
00:15:49,980 --> 00:15:52,860
multiple users clients on my platform

388
00:15:52,860 --> 00:15:57,019
separate indices for each of them

389
00:15:57,600 --> 00:16:00,660
so you can you can choose to pass in

390
00:16:00,660 --> 00:16:03,240
your own user IDs or you can pass the

391
00:16:03,240 --> 00:16:05,399
unique objects in one by one and we can

392
00:16:05,399 --> 00:16:06,839
generate the user IDs if you already

393
00:16:06,839 --> 00:16:09,360
have the user IDs then you can pass them

394
00:16:09,360 --> 00:16:12,060
in when you're passing your data into

395
00:16:12,060 --> 00:16:14,820
ev8 so if you have a look at the quick

396
00:16:14,820 --> 00:16:16,800
start guide on vva it'll show you

397
00:16:16,800 --> 00:16:18,899
exactly how you can specify where your

398
00:16:18,899 --> 00:16:21,000
user IDs would come from

399
00:16:21,000 --> 00:16:22,740
and then if your data is not already

400
00:16:22,740 --> 00:16:24,540
vectorized then you can specify exactly

401
00:16:24,540 --> 00:16:26,220
how you want it to be vectorized as well

402
00:16:26,220 --> 00:16:28,680
let's say you have multiple text fields

403
00:16:28,680 --> 00:16:30,420
or you've got a text field along with

404
00:16:30,420 --> 00:16:33,420
images you can use different modules

405
00:16:33,420 --> 00:16:35,160
that we've already built in to eviate to

406
00:16:35,160 --> 00:16:37,079
vectorize those let's say you have an

407
00:16:37,079 --> 00:16:38,639
image as well as text

408
00:16:38,639 --> 00:16:41,759
you can use the open clip module to uh

409
00:16:41,759 --> 00:16:44,100
to vectorize both of those images and

410
00:16:44,100 --> 00:16:46,500
text together what are some advantages

411
00:16:46,500 --> 00:16:49,079
another question uh some advantages is

412
00:16:49,079 --> 00:16:51,839
weviate have compared to vertex AI

413
00:16:51,839 --> 00:16:53,399
matching engine Pine colon or any other

414
00:16:53,399 --> 00:16:56,699
Vector Source uh yeah so I would say Eva

415
00:16:56,699 --> 00:16:58,860
is completely open source the other

416
00:16:58,860 --> 00:17:00,779
Advantage is that it's built on top of

417
00:17:00,779 --> 00:17:02,339
approximate nearest neighbors search

418
00:17:02,339 --> 00:17:04,520
hnsw technology

419
00:17:04,520 --> 00:17:07,620
and I would say scalability is the

420
00:17:07,620 --> 00:17:10,500
biggest power of weeviate we've tested

421
00:17:10,500 --> 00:17:12,780
this Vector database with a billion data

422
00:17:12,780 --> 00:17:15,079
objects and it scales

423
00:17:15,079 --> 00:17:18,000
very well you can have a billion data

424
00:17:18,000 --> 00:17:19,439
objects in fact the data set that we

425
00:17:19,439 --> 00:17:21,720
tested on was uh from Facebook there's

426
00:17:21,720 --> 00:17:24,120
fear data set and it scaled really well

427
00:17:24,120 --> 00:17:28,319
the query time was very consistent from

428
00:17:28,319 --> 00:17:31,260
a million to a billion objects right so

429
00:17:31,260 --> 00:17:34,200
I think on a small scale uh there's not

430
00:17:34,200 --> 00:17:35,820
that much difference but especially when

431
00:17:35,820 --> 00:17:37,799
you scale scale up and when you want to

432
00:17:37,799 --> 00:17:39,919
take an application into production

433
00:17:39,919 --> 00:17:42,299
we've kind of battle tested this thing

434
00:17:42,299 --> 00:17:44,340
specifically for that and I would say

435
00:17:44,340 --> 00:17:46,440
that those are some of our major

436
00:17:46,440 --> 00:17:49,620
strengths compared to Pinecone or vertex

437
00:17:49,620 --> 00:17:51,980
AI

438
00:17:52,559 --> 00:17:54,120
all right I love the questions you can

439
00:17:54,120 --> 00:17:55,980
keep them coming by the way

440
00:17:55,980 --> 00:17:58,140
okay so where were we on this

441
00:17:58,140 --> 00:18:01,080
uh oh yes group task take all the

442
00:18:01,080 --> 00:18:03,120
returned uh articles and send them to

443
00:18:03,120 --> 00:18:05,760
chatgpt for it to answer a question

444
00:18:05,760 --> 00:18:07,799
by the way these can these can all be

445
00:18:07,799 --> 00:18:10,500
multilingual so the the model itself

446
00:18:10,500 --> 00:18:13,320
does not need to be from open AI the

447
00:18:13,320 --> 00:18:14,880
model itself can be your trained model

448
00:18:14,880 --> 00:18:16,919
or from a third party it can be from

449
00:18:16,919 --> 00:18:19,140
hugging face or cohere that doesn't

450
00:18:19,140 --> 00:18:21,179
matter because it's the actual text

451
00:18:21,179 --> 00:18:23,220
we're sending to chat CPT the it doesn't

452
00:18:23,220 --> 00:18:26,120
care about the embeddings

453
00:18:28,380 --> 00:18:32,460
yeah and this one uh were

454
00:18:32,460 --> 00:18:34,320
we're asking it the same thing but now

455
00:18:34,320 --> 00:18:37,200
we're we're crafting our prompt to be a

456
00:18:37,200 --> 00:18:39,299
little better right so we've chosen not

457
00:18:39,299 --> 00:18:41,100
just all the cricketers but just the the

458
00:18:41,100 --> 00:18:42,720
best cricketers from India

459
00:18:42,720 --> 00:18:45,240
and now it Compares against uh against

460
00:18:45,240 --> 00:18:47,600
these

461
00:18:47,700 --> 00:18:50,280
is streaming indices possible with vva

462
00:18:50,280 --> 00:18:52,320
as I have data streaming in and I want

463
00:18:52,320 --> 00:18:54,059
it to index on the flight does it take a

464
00:18:54,059 --> 00:18:57,059
lot of time uh or indexing takes very

465
00:18:57,059 --> 00:18:58,260
small time

466
00:18:58,260 --> 00:19:00,480
yeah yeah so that's a great question you

467
00:19:00,480 --> 00:19:01,860
can actually for that particular

468
00:19:01,860 --> 00:19:03,720
application I would recommend you look

469
00:19:03,720 --> 00:19:06,660
at this

470
00:19:06,660 --> 00:19:10,559
so weviate has a spark connector

471
00:19:10,559 --> 00:19:14,160
so if you've got data that's streaming

472
00:19:14,160 --> 00:19:16,260
in from spark you can actually stream it

473
00:19:16,260 --> 00:19:20,220
through spark directly to leviate and

474
00:19:20,220 --> 00:19:22,260
it's very very quick so for that

475
00:19:22,260 --> 00:19:23,640
particular application I would recommend

476
00:19:23,640 --> 00:19:24,720
this

477
00:19:24,720 --> 00:19:27,059
can this be used as a database to store

478
00:19:27,059 --> 00:19:29,580
embeddings of a complete Enterprise for

479
00:19:29,580 --> 00:19:30,960
Enterprise search

480
00:19:30,960 --> 00:19:33,360
uh

481
00:19:33,360 --> 00:19:35,160
complete embeddings for an Enterprise

482
00:19:35,160 --> 00:19:36,900
I'm not sure what you mean by Enterprise

483
00:19:36,900 --> 00:19:41,580
but if you mean your your own data

484
00:19:41,580 --> 00:19:43,980
like uh for your for your company's data

485
00:19:43,980 --> 00:19:45,660
for sure right that that's one of the

486
00:19:45,660 --> 00:19:47,580
main applications right

487
00:19:47,580 --> 00:19:49,020
um what you have to be what you have to

488
00:19:49,020 --> 00:19:50,820
choose is how you vectorize that data

489
00:19:50,820 --> 00:19:53,160
how you chunk it up

490
00:19:53,160 --> 00:19:55,140
documents of the Enterprise yeah so if

491
00:19:55,140 --> 00:19:57,960
it's a company proprietary document you

492
00:19:57,960 --> 00:19:59,880
have to you have to be careful how you

493
00:19:59,880 --> 00:20:02,880
chunk it up because how you chunk it up

494
00:20:02,880 --> 00:20:05,100
will determine how you can search over

495
00:20:05,100 --> 00:20:05,960
them

496
00:20:05,960 --> 00:20:08,760
if you take entire documents and you

497
00:20:08,760 --> 00:20:10,440
vectorize those entire documents the

498
00:20:10,440 --> 00:20:12,059
vectorizations are not going to be

499
00:20:12,059 --> 00:20:14,340
they're going to be centroids for those

500
00:20:14,340 --> 00:20:16,080
entire documents so this is one of the

501
00:20:16,080 --> 00:20:18,720
reasons why in the Wikipedia data set we

502
00:20:18,720 --> 00:20:20,299
chunked up

503
00:20:20,299 --> 00:20:24,360
individual paragraphs so but but that's

504
00:20:24,360 --> 00:20:26,400
definitely an application of this you

505
00:20:26,400 --> 00:20:28,380
can definitely take up take company

506
00:20:28,380 --> 00:20:30,059
documents any documents really so if

507
00:20:30,059 --> 00:20:32,039
you're running a legal firm let's say

508
00:20:32,039 --> 00:20:34,140
you can take uh different documents

509
00:20:34,140 --> 00:20:35,520
vectorize them put them into your

510
00:20:35,520 --> 00:20:38,160
database and then you can do uh Vector

511
00:20:38,160 --> 00:20:40,820
search over them

512
00:20:44,220 --> 00:20:46,559
more concerned about the scale

513
00:20:46,559 --> 00:20:50,160
yeah so uh how many uh what scale uh

514
00:20:50,160 --> 00:20:52,919
vectors and how many objects do you guys

515
00:20:52,919 --> 00:20:53,700
have

516
00:20:53,700 --> 00:20:55,320
I can I can

517
00:20:55,320 --> 00:20:59,360
answer more specifically if I know that

518
00:21:00,539 --> 00:21:02,760
while you're while you're letting me

519
00:21:02,760 --> 00:21:05,640
know let me let me finish this uh demo

520
00:21:05,640 --> 00:21:07,679
off here

521
00:21:07,679 --> 00:21:09,480
you can ask it a very interesting

522
00:21:09,480 --> 00:21:11,940
questions here right so

523
00:21:11,940 --> 00:21:14,280
you can ask it why all this text is

524
00:21:14,280 --> 00:21:17,520
similar and you can give it

525
00:21:17,520 --> 00:21:21,299
uh you can give it all cricketers and it

526
00:21:21,299 --> 00:21:23,460
identifies this so this is not very

527
00:21:23,460 --> 00:21:26,460
surprising the last thing here is I I

528
00:21:26,460 --> 00:21:29,280
put in a bunch of uh cricketers here and

529
00:21:29,280 --> 00:21:31,140
then I said tell me a story where all of

530
00:21:31,140 --> 00:21:34,080
these people fight each other and I gave

531
00:21:34,080 --> 00:21:35,820
it all the context of all the people

532
00:21:35,820 --> 00:21:38,840
right so I gave them uh Wikipedia

533
00:21:38,840 --> 00:21:41,280
Wikipedia paragraphs about all of them

534
00:21:41,280 --> 00:21:43,740
and it generates a fairly good story

535
00:21:43,740 --> 00:21:45,780
about how all of these different and

536
00:21:45,780 --> 00:21:47,100
these are the characters of my story

537
00:21:47,100 --> 00:21:49,380
that I got from wevie and I passed it to

538
00:21:49,380 --> 00:21:51,480
chat TPT and it tells a fairly good

539
00:21:51,480 --> 00:21:53,760
story about how

540
00:21:53,760 --> 00:21:55,380
uh

541
00:21:55,380 --> 00:21:57,179
how they can interact in a qriket match

542
00:21:57,179 --> 00:22:00,059
oh okay so maybe 10 000 documents 10 000

543
00:22:00,059 --> 00:22:01,740
documents is no problem

544
00:22:01,740 --> 00:22:04,440
like I said um we V8 has been tested

545
00:22:04,440 --> 00:22:08,580
with a billion documents uh so depending

546
00:22:08,580 --> 00:22:11,280
on how you I should say a billion object

547
00:22:11,280 --> 00:22:13,799
so the sphere data set has a billion uh

548
00:22:13,799 --> 00:22:16,320
data objects if you take your 10 000

549
00:22:16,320 --> 00:22:18,539
documents let's say you chunk it up and

550
00:22:18,539 --> 00:22:21,120
you tokenize them or you uh you segment

551
00:22:21,120 --> 00:22:23,340
it such that it turns into one million

552
00:22:23,340 --> 00:22:25,559
documents you can easily search over

553
00:22:25,559 --> 00:22:27,780
that store that into eviate

554
00:22:27,780 --> 00:22:30,720
um the only uh the thing that might take

555
00:22:30,720 --> 00:22:33,000
time is when you vectorize them right so

556
00:22:33,000 --> 00:22:34,200
you want to make sure that you choose

557
00:22:34,200 --> 00:22:36,780
the right vectorizer uh to vectorize

558
00:22:36,780 --> 00:22:38,640
them and then once it's vectorized then

559
00:22:38,640 --> 00:22:41,520
you can query query them very quickly

560
00:22:41,520 --> 00:22:44,539
it's not a problem

561
00:22:44,580 --> 00:22:46,620
another question let's say we want to

562
00:22:46,620 --> 00:22:50,100
build a chat bot for follow-up q a

563
00:22:50,100 --> 00:22:52,559
uh whereas the user replies context

564
00:22:52,559 --> 00:22:54,179
changes what would be the best way to

565
00:22:54,179 --> 00:22:55,980
approach that shall we vectorize and

566
00:22:55,980 --> 00:22:58,500
index all possible conversations and

567
00:22:58,500 --> 00:23:00,000
whenever a user asks a follow-up

568
00:23:00,000 --> 00:23:02,100
question search for similar questions

569
00:23:02,100 --> 00:23:04,740
and find corresponding reply given oh

570
00:23:04,740 --> 00:23:07,740
this is this is pretty awesome so

571
00:23:07,740 --> 00:23:10,980
just to answer that question we had a

572
00:23:10,980 --> 00:23:15,120
recent blog that was was written up here

573
00:23:15,120 --> 00:23:17,700
and it's interesting because this blog

574
00:23:17,700 --> 00:23:19,620
answers exactly your question

575
00:23:19,620 --> 00:23:21,900
the idea here is

576
00:23:21,900 --> 00:23:24,659
if you want to create a chat bot

577
00:23:24,659 --> 00:23:28,140
um you can't just uh you can't just ask

578
00:23:28,140 --> 00:23:31,640
you can't just send individual questions

579
00:23:31,640 --> 00:23:34,799
to chat CPT you have to send it the

580
00:23:34,799 --> 00:23:36,900
context of previous questions and the

581
00:23:36,900 --> 00:23:39,360
way you do that is by combining vv8 with

582
00:23:39,360 --> 00:23:41,700
Lang chain and Lang chain allows you to

583
00:23:41,700 --> 00:23:43,380
take the context of previous

584
00:23:43,380 --> 00:23:45,960
conversations wrap it up put it into

585
00:23:45,960 --> 00:23:49,320
your vector database and then send all

586
00:23:49,320 --> 00:23:52,440
of that relevant information to uh to

587
00:23:52,440 --> 00:23:54,299
chat CPT

588
00:23:54,299 --> 00:23:56,940
and so let me show you an example of

589
00:23:56,940 --> 00:23:57,960
this

590
00:23:57,960 --> 00:24:00,419
so let's say you've got a conversation

591
00:24:00,419 --> 00:24:03,120
going on with the chatbot

592
00:24:03,120 --> 00:24:05,820
you can get you can take its answers put

593
00:24:05,820 --> 00:24:09,419
it into eviate and then get it to uh

594
00:24:09,419 --> 00:24:12,059
answer questions uh with regards to its

595
00:24:12,059 --> 00:24:15,020
own previous answers

596
00:24:16,020 --> 00:24:17,820
can you please point to the document

597
00:24:17,820 --> 00:24:19,380
which mentions that you have tested with

598
00:24:19,380 --> 00:24:22,020
one billion documents yes for sure so

599
00:24:22,020 --> 00:24:24,480
that is another blog post here

600
00:24:24,480 --> 00:24:28,640
so this is over here

601
00:24:28,980 --> 00:24:31,440
if you look at

602
00:24:31,440 --> 00:24:34,980
and we did this at the end of last year

603
00:24:34,980 --> 00:24:37,700
let me just pull this up

604
00:24:37,700 --> 00:24:40,140
so if you want to read

605
00:24:40,140 --> 00:24:42,600
about the data set that we put in this

606
00:24:42,600 --> 00:24:44,100
is the blog post that you want to read

607
00:24:44,100 --> 00:24:45,720
that I wrote over here

608
00:24:45,720 --> 00:24:48,480
so the sphere data set in vva and if you

609
00:24:48,480 --> 00:24:50,280
want to know what type of hardware and

610
00:24:50,280 --> 00:24:51,960
software we use to test the whole thing

611
00:24:51,960 --> 00:24:54,299
there's a follow-up blog post here that

612
00:24:54,299 --> 00:24:58,080
goes over uh everything and I can share

613
00:24:58,080 --> 00:25:00,840
these links in the chat here for all of

614
00:25:00,840 --> 00:25:03,620
you that are interested

615
00:25:05,880 --> 00:25:08,159
so that's the one that covers the

616
00:25:08,159 --> 00:25:11,520
metrics how how ev8 held up as we were

617
00:25:11,520 --> 00:25:13,559
uploading data

618
00:25:13,559 --> 00:25:16,860
uh so in in fact here we got up to 900

619
00:25:16,860 --> 00:25:20,400
million objects and there was a linear

620
00:25:20,400 --> 00:25:21,720
performance here

621
00:25:21,720 --> 00:25:23,520
um as we were inserting the objects into

622
00:25:23,520 --> 00:25:26,159
eviate and the data set is only as big

623
00:25:26,159 --> 00:25:28,380
as this right and you can read more

624
00:25:28,380 --> 00:25:29,700
about the

625
00:25:29,700 --> 00:25:32,580
about the data set here and I will also

626
00:25:32,580 --> 00:25:34,860
link the

627
00:25:34,860 --> 00:25:37,559
the length chain where you can pass the

628
00:25:37,559 --> 00:25:38,880
line chain blog post where you can pass

629
00:25:38,880 --> 00:25:42,120
in uh context

630
00:25:42,120 --> 00:25:44,700
all right uh

631
00:25:44,700 --> 00:25:46,380
there's another question is there any

632
00:25:46,380 --> 00:25:48,120
integration of

633
00:25:48,120 --> 00:25:52,020
Lambda index GPT index with vv8 yes so

634
00:25:52,020 --> 00:25:53,400
if you want to learn more about that

635
00:25:53,400 --> 00:25:55,799
there's actually a Blog there's actually

636
00:25:55,799 --> 00:25:59,159
a podcast that we recently did with the

637
00:25:59,159 --> 00:26:01,440
founder of uh GPT index and that's on

638
00:26:01,440 --> 00:26:03,539
our YouTube channel so you can you can

639
00:26:03,539 --> 00:26:06,179
learn about that and you can also read

640
00:26:06,179 --> 00:26:09,260
about it in our Docs

641
00:26:09,419 --> 00:26:11,580
this is awesome

642
00:26:11,580 --> 00:26:13,140
thanks everybody that's that's

643
00:26:13,140 --> 00:26:14,760
everything that I had unless there's any

644
00:26:14,760 --> 00:26:15,900
more questions

645
00:26:15,900 --> 00:26:18,360
have fun with the hackathon and if you

646
00:26:18,360 --> 00:26:21,059
make something cool with weeviate join

647
00:26:21,059 --> 00:26:22,740
us on our slack Community share it with

648
00:26:22,740 --> 00:26:26,960
us we always love to hear about it

649
00:26:28,860 --> 00:26:32,419
all right thank you folks
